{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read the 00 pickle file\n",
    "tweets_00 = pd.read_pickle('pickleFiles/tweets_00_Pickle.pkl')\n",
    "total = pd.DataFrame()\n",
    "total = total.append(tweets_00)\n",
    "del tweets_00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read the 01 pickle file\n",
    "data01 = pd.read_pickle('tweets_01_Pickle.pkl')\n",
    "total = total.append(data01)\n",
    "del data01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Read the 02 pickle file\n",
    "# data02 = pd.read_pickle('tweets_02_Pickle.pkl')\n",
    "# total = total.append(data02)\n",
    "# del data02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to Pickle File\n",
    "total.to_pickle('twitterDataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the 01 pickle files\n",
    "# tweets_01_1 = pd.read_pickle('pickleFiles/tweets_01_01_Pickle.pkl')\n",
    "# tweets_01_2 = pd.read_pickle('pickleFiles/tweets_01_02_Pickle.pkl')\n",
    "# # tweets_01_3 = pd.read_pickle('pickleFiles/tweets_01_03_Pickle.pkl')\n",
    "# tweets_01_4 = pd.read_pickle('pickleFiles/tweets_01_04_Pickle.pkl')\n",
    "# tweets_01_5 = pd.read_pickle('pickleFiles/tweets_01_05_Pickle.pkl')\n",
    "# tweets_01_6 = pd.read_pickle('pickleFiles/tweets_01_06_Pickle.pkl')\n",
    "# tweets_01_7 = pd.read_pickle('pickleFiles/tweets_01_07_Pickle.pkl')\n",
    "# tweets_01_8 = pd.read_pickle('pickleFiles/tweets_01_08_Pickle.pkl')\n",
    "# tweets_01_9 = pd.read_pickle('pickleFiles/tweets_01_09_Pickle.pkl')\n",
    "# tweets_01_10 = pd.read_pickle('pickleFiles/tweets_01_10_Pickle.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the 02 pickle files\n",
    "# tweets_02_1 = pd.read_pickle('pickleFiles/tweets_02_01_Pickle.pkl')\n",
    "# # tweets_02_2 = pd.read_pickle('pickleFiles/tweets_02_02_Pickle.pkl')\n",
    "# tweets_02_3 = pd.read_pickle('pickleFiles/tweets_02_03_Pickle.pkl')\n",
    "# tweets_02_4 = pd.read_pickle('pickleFiles/tweets_02_04_Pickle.pkl')\n",
    "# tweets_02_5 = pd.read_pickle('pickleFiles/tweets_02_05_Pickle.pkl')\n",
    "# tweets_02_6 = pd.read_pickle('pickleFiles/tweets_02_06_Pickle.pkl')\n",
    "# tweets_02_7 = pd.read_pickle('pickleFiles/tweets_02_07_Pickle.pkl')\n",
    "# tweets_02_8 = pd.read_pickle('pickleFiles/tweets_02_08_Pickle.pkl')\n",
    "# tweets_02_9 = pd.read_pickle('pickleFiles/tweets_02_09_Pickle.pkl')\n",
    "# tweets_02_10 = pd.read_pickle('pickleFiles/tweets_02_10_Pickle.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Dataframes for 01 and 02\n",
    "# data01 = pd.DataFrame()\n",
    "# data02 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Append 01\n",
    "# data01 = data01.append(tweets_01_1)\n",
    "# data01 = data01.append(tweets_01_2)\n",
    "# data01 = data01.append(tweets_01_4)\n",
    "# data01 = data01.append(tweets_01_5)\n",
    "# data01 = data01.append(tweets_01_6)\n",
    "# data01 = data01.append(tweets_01_7)\n",
    "# data01 = data01.append(tweets_01_8)\n",
    "# data01 = data01.append(tweets_01_9)\n",
    "# data01 = data01.append(tweets_01_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write 01 to file\n",
    "# data01.to_pickle('tweets_01_Pickle.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Append 02\n",
    "# data02 = data02.append(tweets_02_1)\n",
    "# data02 = data02.append(tweets_02_3)\n",
    "# data02 = data02.append(tweets_02_4)\n",
    "# data02 = data02.append(tweets_02_5)\n",
    "# data02 = data02.append(tweets_02_6)\n",
    "# data02 = data02.append(tweets_02_7)\n",
    "# data02 = data02.append(tweets_02_8)\n",
    "# data02 = data02.append(tweets_02_9)\n",
    "# data02 = data02.append(tweets_02_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write 02 to file\n",
    "# data02.to_pickle('tweets_02_Pickle.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinates</th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>place</th>\n",
       "      <th>text</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954403129184256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[gotta, love, fact]</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954356572250112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[great, day, action, message, dear, dan, toola...</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954497341480960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[harvey, norman, reckons, climate, change, bun...</td>\n",
       "      <td>Noble Park,Oz, Khon Kaen Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954494133043200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[skepticism, immigration, walk, hand, hand, sk...</td>\n",
       "      <td>Toronto, Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954811511844864</td>\n",
       "      <td>climatechange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[th, november, creative, citizen, w, practical...</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700284</th>\n",
       "      <td>NaN</td>\n",
       "      <td>981117160788553729</td>\n",
       "      <td>risingseas climatechange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[mum, mum, water, here, coastal, saintlouis, s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700285</th>\n",
       "      <td>NaN</td>\n",
       "      <td>981117592604590082</td>\n",
       "      <td>workshop SDG climate BUP ClimateChange Environ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[day, long, action, held]</td>\n",
       "      <td>Dhaka, Bangladesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700286</th>\n",
       "      <td>NaN</td>\n",
       "      <td>981117022858657792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[global, warming]</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700287</th>\n",
       "      <td>NaN</td>\n",
       "      <td>981117118660755456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[climate, change, lucifer, heatwave, far, like...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700288</th>\n",
       "      <td>NaN</td>\n",
       "      <td>981117523666989058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[saying, climate, change, exist]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13470832 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       coordinates                   id  \\\n",
       "0              NaN  1028954403129184256   \n",
       "1              NaN  1028954356572250112   \n",
       "2              NaN  1028954497341480960   \n",
       "3              NaN  1028954494133043200   \n",
       "4              NaN  1028954811511844864   \n",
       "...            ...                  ...   \n",
       "700284         NaN   981117160788553729   \n",
       "700285         NaN   981117592604590082   \n",
       "700286         NaN   981117022858657792   \n",
       "700287         NaN   981117118660755456   \n",
       "700288         NaN   981117523666989058   \n",
       "\n",
       "                                                 hashtags place  \\\n",
       "0                                                     NaN   NaN   \n",
       "1                                                     NaN   NaN   \n",
       "2                                                     NaN   NaN   \n",
       "3                                                     NaN   NaN   \n",
       "4                                           climatechange   NaN   \n",
       "...                                                   ...   ...   \n",
       "700284                           risingseas climatechange   NaN   \n",
       "700285  workshop SDG climate BUP ClimateChange Environ...   NaN   \n",
       "700286                                                NaN   NaN   \n",
       "700287                                                NaN   NaN   \n",
       "700288                                                NaN   NaN   \n",
       "\n",
       "                                                     text  \\\n",
       "0                                     [gotta, love, fact]   \n",
       "1       [great, day, action, message, dear, dan, toola...   \n",
       "2       [harvey, norman, reckons, climate, change, bun...   \n",
       "3       [skepticism, immigration, walk, hand, hand, sk...   \n",
       "4       [th, november, creative, citizen, w, practical...   \n",
       "...                                                   ...   \n",
       "700284  [mum, mum, water, here, coastal, saintlouis, s...   \n",
       "700285                          [day, long, action, held]   \n",
       "700286                                  [global, warming]   \n",
       "700287  [climate, change, lucifer, heatwave, far, like...   \n",
       "700288                   [saying, climate, change, exist]   \n",
       "\n",
       "                        user_location  \n",
       "0                       United States  \n",
       "1                           Australia  \n",
       "2       Noble Park,Oz, Khon Kaen Thai  \n",
       "3                    Toronto, Ontario  \n",
       "4                     Dublin, Ireland  \n",
       "...                               ...  \n",
       "700284                            NaN  \n",
       "700285              Dhaka, Bangladesh  \n",
       "700286                Los Angeles, CA  \n",
       "700287                            NaN  \n",
       "700288                            NaN  \n",
       "\n",
       "[13470832 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
