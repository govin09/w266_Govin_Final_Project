{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gov_m\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from datetime import datetime\n",
    "import preprocessor as p\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "nltk.download\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Read the tweet file to a dataframe \n",
    "tweets = pd.read_csv('tweets_00.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>place</th>\n",
       "      <th>text</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954403129184256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gotta love the facts. https://t.co/bZ2G8AZuo9</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954356572250112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ToolangiForest: A great day of action for ...</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954497341480960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@jonkudelka Harvey Norman reckons climate chan...</td>\n",
       "      <td>Noble Park,Oz, Khon Kaen Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954494133043200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @jayrosen_nyu: Why does skepticism about im...</td>\n",
       "      <td>Toronto, Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954811511844864</td>\n",
       "      <td>climatechange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @FranceinIreland: On 5th November we call a...</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 coordinates                   id       hashtags place  \\\n",
       "0           0         NaN  1028954403129184256            NaN   NaN   \n",
       "1           1         NaN  1028954356572250112            NaN   NaN   \n",
       "2           2         NaN  1028954497341480960            NaN   NaN   \n",
       "3           3         NaN  1028954494133043200            NaN   NaN   \n",
       "4           4         NaN  1028954811511844864  climatechange   NaN   \n",
       "\n",
       "                                                text  \\\n",
       "0      Gotta love the facts. https://t.co/bZ2G8AZuo9   \n",
       "1  RT @ToolangiForest: A great day of action for ...   \n",
       "2  @jonkudelka Harvey Norman reckons climate chan...   \n",
       "3  RT @jayrosen_nyu: Why does skepticism about im...   \n",
       "4  RT @FranceinIreland: On 5th November we call a...   \n",
       "\n",
       "                   user_location  \n",
       "0                  United States  \n",
       "1                      Australia  \n",
       "2  Noble Park,Oz, Khon Kaen Thai  \n",
       "3               Toronto, Ontario  \n",
       "4                Dublin, Ireland  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-Check\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       7194837\n",
       "coordinates         1955\n",
       "id               7194837\n",
       "hashtags         1760731\n",
       "place              83115\n",
       "text             7194837\n",
       "user_location    5431846\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-Check\n",
    "tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 448 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Drop Unnamed Columns\n",
    "tweets = tweets.drop(columns='Unnamed: 0')\n",
    "# tweets = tweets.drop(columns='Unnamed: 0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Process Function\n",
    "def preprocess_tweet(row):\n",
    "    # Function for cleaning text - removal of URLs, Mentions\n",
    "    # Using tweet-preprocessor package\n",
    "    text = p.clean(row['text'])\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Function for Punctuation Removal, Replace extra white spaces, stopwords removal\n",
    "    # Using gensim package\n",
    "    text = remove_stopwords(text)\n",
    "    \n",
    "    # Remove extra white spaces\n",
    "    text = text.replace('[^\\w\\s]',' ').replace('\\s\\s+', ' ')\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove Digits\n",
    "    text = text.replace('\\d+', '')\n",
    "    \n",
    "    # Lemmatization + Tokenization\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    w_tokenizer = TweetTokenizer()\n",
    "    \n",
    "    text = [(lemmatizer.lemmatize(w)) for w in w_tokenizer.tokenize((text))]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Run Preprocessing\n",
    "tweets['text'] = tweets.apply(preprocess_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinates</th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>place</th>\n",
       "      <th>text</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954403129184256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[gotta, love, fact]</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954356572250112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[great, day, action, message, dear, dan, toola...</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954497341480960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[harvey, norman, reckons, climate, change, bun...</td>\n",
       "      <td>Noble Park,Oz, Khon Kaen Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954494133043200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[skepticism, immigration, walk, hand, hand, sk...</td>\n",
       "      <td>Toronto, Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1028954811511844864</td>\n",
       "      <td>climatechange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[th, november, creative, citizen, w, practical...</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  coordinates                   id       hashtags place  \\\n",
       "0         NaN  1028954403129184256            NaN   NaN   \n",
       "1         NaN  1028954356572250112            NaN   NaN   \n",
       "2         NaN  1028954497341480960            NaN   NaN   \n",
       "3         NaN  1028954494133043200            NaN   NaN   \n",
       "4         NaN  1028954811511844864  climatechange   NaN   \n",
       "\n",
       "                                                text  \\\n",
       "0                                [gotta, love, fact]   \n",
       "1  [great, day, action, message, dear, dan, toola...   \n",
       "2  [harvey, norman, reckons, climate, change, bun...   \n",
       "3  [skepticism, immigration, walk, hand, hand, sk...   \n",
       "4  [th, november, creative, citizen, w, practical...   \n",
       "\n",
       "                   user_location  \n",
       "0                  United States  \n",
       "1                      Australia  \n",
       "2  Noble Park,Oz, Khon Kaen Thai  \n",
       "3               Toronto, Ontario  \n",
       "4                Dublin, Ireland  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_pickle('tweets_00_Pickle.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
